{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "from prettytable import PrettyTable\n",
    "from termcolor import cprint\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from plotly.offline import iplot\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% FUNCTION FOR FORWARD FEATURE SELECTION\n",
    "\n",
    "def forward_selection(df):\n",
    "    from sklearn.feature_selection import f_regression\n",
    "    df=df.fillna(df.mean())\n",
    "    le = LabelEncoder()\n",
    "    cat_cols=list(df.select_dtypes('object').columns)\n",
    "    for fet in cat_cols:\n",
    "        #le.fit(df[fet])\n",
    "        df[fet] = le.fit_transform(df[fet].astype(str))\n",
    "    target=input('ENTER THE TARGET VARIABLE : ')\n",
    "    Target=df[target]\n",
    "    X=df.drop(columns=target)\n",
    "    ffs = f_regression(X,Target)\n",
    "    t = Table([X.columns, ffs[0], ffs[1]], names=('FEATURES', 'f-Value', 'p-Value'))\n",
    "    print(t)\n",
    "    #print(ffs)\n",
    "    #data = {'names': ffs[0], 'values': ffs[1]}\n",
    "    #df1 = pandas.DataFrame(data=data)\n",
    "    #print(df1)\n",
    "    variable = [ ]\n",
    "    threshold=int(input(\"Enter f_value : (integer value ranging from 10 to 80)\"))\n",
    "    for i in range(0,len(df.columns)-1):\n",
    "        if ffs[0][i] >=threshold:\n",
    "            variable.append(df.columns[i])\n",
    "    return variable     ##this is list of accepted variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_elimination(df):\n",
    "    import statsmodels.api as sm\n",
    "    df=df.fillna(df.mean())\n",
    "    le = LabelEncoder()\n",
    "    cat_cols=list(df.select_dtypes('object').columns)\n",
    "    for fet in cat_cols:\n",
    "        #le.fit(df[fet])\n",
    "        df[fet] = le.fit_transform(df[fet].astype(str))\n",
    "    features = df.columns.tolist()\n",
    "    target=input('ENTER THE TARGET VARIABLE : ')\n",
    "    Target=df[target]\n",
    "    X=df.drop(columns=target)\n",
    "    threshold=float(input(\"Choose a significance level 0.01 to 0.05\"))\n",
    "    while(len(features)>0):\n",
    "        features_with_constant = sm.add_constant(df[features])\n",
    "        p_values = sm.OLS(Target, features_with_constant.astype(float)).fit().pvalues[1:]\n",
    "        max_p_value = p_values.max()\n",
    "        if(max_p_value >= threshold):\n",
    "            excluded_feature = p_values.idxmax()\n",
    "            features.remove(excluded_feature)\n",
    "        else:\n",
    "            break \n",
    "        print(p_values)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% FUNCTION FOR CLUSTERING\n",
    "\n",
    "def clustering(df):\n",
    "    df=df.fillna(df.mean())\n",
    "    le = LabelEncoder()\n",
    "    cat_cols=list(df.select_dtypes('object').columns)\n",
    "    for fet in cat_cols:\n",
    "        #le.fit(df[fet])\n",
    "        df[fet] = le.fit_transform(df[fet].astype(str))\n",
    "    initial_features = df.columns.tolist()\n",
    "    target=input('ENTER THE TARGET VARIABLE : ')\n",
    "    Target=df[target]\n",
    "    X=df.drop(columns=target)\n",
    "    from varclushi import VarClusHi\n",
    "    threshold=float(input(\"Enter eigenvalue : (range 0.1 to 1.0)\"))\n",
    "    var_model=VarClusHi(X,maxeigval2 =threshold,maxclus=None) ##I used maxeigval = 0.7. It means that clusters will split if the second eigenvalue is greater than 0.7. A larger value of this parameter gives fewer clusters and less of the variations explained. Smaller value gives more clusters and more variation explained. The common choice is 1 as it represents the average size of eigenvalues.\n",
    "    var_model.varclus()\n",
    "    print(var_model.rsquare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
